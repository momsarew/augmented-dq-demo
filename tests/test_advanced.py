"""
Tests avanc√©s du Framework Probabiliste DQ
==========================================

Ce fichier teste :
1. Les calculs Beta (vecteurs 4D)
2. Les pond√©rations AHP
3. Les scores de risque
4. Le calcul d'unicit√© DAMA
5. La propagation lineage
6. La coh√©rence globale du syst√®me
"""

import os
import sys
import pandas as pd
import numpy as np

# Ajouter les chemins
PROJECT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
ENGINE_DIR = os.path.join(PROJECT_DIR, "backend", "engine")
sys.path.insert(0, PROJECT_DIR)
sys.path.insert(0, ENGINE_DIR)

# Imports des modules
os.chdir(ENGINE_DIR)
import analyzer
import beta_calculator
import ahp_elicitor
import risk_scorer
import lineage_propagator
import comparator
os.chdir(PROJECT_DIR)

# ============================================================================
# DONN√âES DE TEST
# ============================================================================

def create_test_dataset():
    """Cr√©e un dataset de test avec diff√©rents cas de figure"""
    np.random.seed(42)
    n = 100

    return pd.DataFrame({
        # Colonne parfaite (100% qualit√©)
        "Col_Parfaite": range(1, n+1),

        # Colonne avec 10% de nulls
        "Col_10pct_Nulls": [None if i < 10 else i for i in range(n)],

        # Colonne avec 50% de nulls
        "Col_50pct_Nulls": [None if i < 50 else i for i in range(n)],

        # Colonne avec doublons (unicit√© basse)
        "Col_Doublons": ["A"] * 80 + ["B"] * 15 + ["C"] * 5,

        # Colonne unique (unicit√© haute)
        "Col_Unique": [f"ID_{i:04d}" for i in range(n)],

        # Colonne avec erreurs de type (VARCHAR au lieu de NUMBER)
        "Col_TypeError": ["1,234"] * 30 + [1234] * 70,

        # Colonne dates avec formats mixtes
        "Col_Dates_Mixtes": ["2024-01-15"] * 40 + ["15/01/2024"] * 30 + ["Jan 15, 2024"] * 30,

        # Colonne avec valeurs n√©gatives (violation m√©tier)
        "Col_Salaires": [50000 + np.random.randint(-5000, 10000) for _ in range(95)] + [-1000, -500, -200, 0, 0],
    })


# ============================================================================
# TEST 1: ANALYZER
# ============================================================================

def test_analyzer():
    """Test du module analyzer"""
    print("\n" + "="*60)
    print("TEST 1: ANALYZER")
    print("="*60)

    df = create_test_dataset()
    cols = df.columns.tolist()

    stats = analyzer.analyze_dataset(df, cols)

    print(f"\n‚úÖ Analyse de {len(cols)} colonnes r√©ussie")

    # V√©rifier Col_Parfaite
    assert stats["Col_Parfaite"]["null_rate"] == 0.0, "Col_Parfaite devrait avoir 0% nulls"
    print(f"   Col_Parfaite: null_rate = {stats['Col_Parfaite']['null_rate']:.1%} ‚úì")

    # V√©rifier Col_10pct_Nulls
    assert abs(stats["Col_10pct_Nulls"]["null_rate"] - 0.10) < 0.01, "Col_10pct_Nulls devrait avoir ~10% nulls"
    print(f"   Col_10pct_Nulls: null_rate = {stats['Col_10pct_Nulls']['null_rate']:.1%} ‚úì")

    # V√©rifier Col_50pct_Nulls
    assert abs(stats["Col_50pct_Nulls"]["null_rate"] - 0.50) < 0.01, "Col_50pct_Nulls devrait avoir ~50% nulls"
    print(f"   Col_50pct_Nulls: null_rate = {stats['Col_50pct_Nulls']['null_rate']:.1%} ‚úì")

    return stats


# ============================================================================
# TEST 2: BETA CALCULATOR (Vecteurs 4D)
# ============================================================================

def test_beta_calculator(stats):
    """Test du calcul des vecteurs 4D"""
    print("\n" + "="*60)
    print("TEST 2: BETA CALCULATOR (Vecteurs 4D)")
    print("="*60)

    df = create_test_dataset()
    cols = df.columns.tolist()

    vecteurs = beta_calculator.compute_all_beta_vectors(df, cols, stats)

    print(f"\n‚úÖ Calcul de {len(vecteurs)} vecteurs 4D r√©ussi")

    for col, v in vecteurs.items():
        p_db = v.get("P_DB", 0)
        p_dp = v.get("P_DP", 0)
        p_br = v.get("P_BR", 0)
        p_up = v.get("P_UP", 0)

        # V√©rifier que toutes les probabilit√©s sont entre 0 et 1
        assert 0 <= p_db <= 1, f"{col}: P_DB={p_db} hors limites"
        assert 0 <= p_dp <= 1, f"{col}: P_DP={p_dp} hors limites"
        assert 0 <= p_br <= 1, f"{col}: P_BR={p_br} hors limites"
        assert 0 <= p_up <= 1, f"{col}: P_UP={p_up} hors limites"

        print(f"   {col}: P_DB={p_db:.2f}, P_DP={p_dp:.2f}, P_BR={p_br:.2f}, P_UP={p_up:.2f} ‚úì")

    # V√©rifier que Col_50pct_Nulls a un P_UP √©lev√© (probl√®me d'utilisabilit√©)
    assert vecteurs["Col_50pct_Nulls"]["P_UP"] > 0.3, "Col_50pct_Nulls devrait avoir P_UP √©lev√©"
    print(f"\n   Col_50pct_Nulls a P_UP √©lev√© ({vecteurs['Col_50pct_Nulls']['P_UP']:.2f}) ‚úì")

    return vecteurs


# ============================================================================
# TEST 3: AHP ELICITOR (Pond√©rations)
# ============================================================================

def test_ahp_elicitor():
    """Test du module d'√©licitation AHP"""
    print("\n" + "="*60)
    print("TEST 3: AHP ELICITOR (Pond√©rations)")
    print("="*60)

    ahp = ahp_elicitor.AHPElicitor()

    # Tester les presets
    usages = ["paie_reglementaire", "reporting_social", "dashboard_operationnel", "audit_conformite"]

    for usage in usages:
        weights = ahp.get_weights_preset(usage)

        # V√©rifier que la somme = 1
        total = weights.get("w_DB", 0) + weights.get("w_DP", 0) + weights.get("w_BR", 0) + weights.get("w_UP", 0)
        assert abs(total - 1.0) < 0.01, f"{usage}: somme des poids = {total} (devrait √™tre 1.0)"

        print(f"   {usage}: w_DB={weights['w_DB']:.2f}, w_DP={weights['w_DP']:.2f}, w_BR={weights['w_BR']:.2f}, w_UP={weights['w_UP']:.2f}, Œ£={total:.2f} ‚úì")

    # V√©rifier que Paie privil√©gie DB (structure critique)
    paie = ahp.get_weights_preset("paie_reglementaire")
    assert paie["w_DB"] >= paie["w_UP"], "Paie devrait privil√©gier DB sur UP"
    print(f"\n   Paie privil√©gie DB ({paie['w_DB']:.2f}) sur UP ({paie['w_UP']:.2f}) ‚úì")

    # V√©rifier que Dashboard privil√©gie UP (utilisabilit√©)
    dash = ahp.get_weights_preset("dashboard_operationnel")
    assert dash["w_UP"] >= dash["w_DB"], "Dashboard devrait privil√©gier UP sur DB"
    print(f"   Dashboard privil√©gie UP ({dash['w_UP']:.2f}) sur DB ({dash['w_DB']:.2f}) ‚úì")

    return True


# ============================================================================
# TEST 4: RISK SCORER (Scores de risque)
# ============================================================================

def test_risk_scorer(vecteurs):
    """Test du calcul des scores de risque"""
    print("\n" + "="*60)
    print("TEST 4: RISK SCORER (Scores de risque)")
    print("="*60)

    ahp = ahp_elicitor.AHPElicitor()

    usages = [
        {"nom": "Paie", "type": "paie_reglementaire", "criticite": "HIGH"},
        {"nom": "Dashboard", "type": "dashboard_operationnel", "criticite": "MEDIUM"},
    ]

    weights = {u["nom"]: ahp.get_weights_preset(u["type"]) for u in usages}

    scores = risk_scorer.compute_risk_scores(vecteurs, weights, usages)

    print(f"\n‚úÖ Calcul de {len(scores)} scores de risque r√©ussi")

    for key, score in scores.items():
        # V√©rifier que le score est entre 0 et 1
        assert 0 <= score <= 1, f"{key}: score={score} hors limites"

        # D√©terminer le niveau
        if score >= 0.40:
            niveau = "üî¥ CRITIQUE"
        elif score >= 0.25:
            niveau = "üü† √âLEV√â"
        elif score >= 0.15:
            niveau = "üü° MOD√âR√â"
        else:
            niveau = "üü¢ FAIBLE"

        print(f"   {key}: {score:.1%} {niveau}")

    # V√©rifier que la m√™me colonne a des scores diff√©rents selon l'usage
    # (c'est le c≈ìur du concept probabiliste)
    col_test = "Col_50pct_Nulls"
    score_paie = scores.get(f"{col_test}_Paie", 0)
    score_dash = scores.get(f"{col_test}_Dashboard", 0)

    print(f"\n   M√™me colonne, scores diff√©rents selon usage:")
    print(f"   {col_test}_Paie: {score_paie:.1%}")
    print(f"   {col_test}_Dashboard: {score_dash:.1%}")
    print(f"   ‚Üí Diff√©rence: {abs(score_paie - score_dash):.1%} ‚úì")

    return scores


# ============================================================================
# TEST 5: UNICIT√â DAMA
# ============================================================================

def test_dama_uniqueness():
    """Test du calcul d'unicit√© DAMA"""
    print("\n" + "="*60)
    print("TEST 5: UNICIT√â DAMA")
    print("="*60)

    df = create_test_dataset()
    dama_calc = comparator.DAMACalculator()

    # Test Col_Unique (devrait √™tre ~100%)
    score_unique = dama_calc.compute_dama_score(df, "Col_Unique")
    print(f"\n   Col_Unique (toutes valeurs diff√©rentes):")
    print(f"   ‚Üí Unicit√©: {score_unique['uniqueness']:.1%}")
    assert score_unique['uniqueness'] > 0.99, "Col_Unique devrait avoir unicit√© ~100%"
    print(f"   ‚úì Unicit√© proche de 100%")

    # Test Col_Doublons (80% A, 15% B, 5% C ‚Üí beaucoup de doublons)
    score_doublons = dama_calc.compute_dama_score(df, "Col_Doublons")
    print(f"\n   Col_Doublons (80% m√™me valeur):")
    print(f"   ‚Üí Unicit√©: {score_doublons['uniqueness']:.1%}")
    assert score_doublons['uniqueness'] < 0.10, "Col_Doublons devrait avoir unicit√© tr√®s basse"
    print(f"   ‚úì Unicit√© basse (beaucoup de doublons)")

    # Test Col_Parfaite (valeurs 1-100, toutes uniques)
    score_parfaite = dama_calc.compute_dama_score(df, "Col_Parfaite")
    print(f"\n   Col_Parfaite (1 √† 100, toutes uniques):")
    print(f"   ‚Üí Unicit√©: {score_parfaite['uniqueness']:.1%}")
    print(f"   ‚Üí Compl√©tude: {score_parfaite['completeness']:.1%}")
    assert score_parfaite['uniqueness'] == 1.0, "Col_Parfaite devrait avoir unicit√© 100%"
    assert score_parfaite['completeness'] == 1.0, "Col_Parfaite devrait avoir compl√©tude 100%"
    print(f"   ‚úì Parfaite qualit√©")

    return True


# ============================================================================
# TEST 6: LINEAGE PROPAGATION
# ============================================================================

def test_lineage_propagation(vecteurs):
    """Test de la propagation du risque via lineage"""
    print("\n" + "="*60)
    print("TEST 6: LINEAGE PROPAGATION")
    print("="*60)

    ahp = ahp_elicitor.AHPElicitor()
    weights = ahp.get_weights_preset("paie_reglementaire")

    # Prendre un vecteur de test
    vecteur_test = vecteurs.get("Col_TypeError", vecteurs[list(vecteurs.keys())[0]])

    lineage = lineage_propagator.simulate_lineage(vecteur_test, weights)

    risk_source = lineage.get("risk_source", 0)
    risk_final = lineage.get("risk_final", 0)

    print(f"\n   Risque source: {risk_source:.1%}")
    print(f"   Risque final (apr√®s ETL): {risk_final:.1%}")
    print(f"   D√©gradation: +{(risk_final - risk_source):.1%}")

    # Le risque final devrait √™tre >= risque source (l'ETL d√©grade)
    assert risk_final >= risk_source, "Le risque final devrait √™tre >= risque source"
    print(f"   ‚úì Le risque se propage correctement")

    return True


# ============================================================================
# TEST 7: COMPARAISON DAMA vs PROBABILISTE
# ============================================================================

def test_dama_vs_probabiliste(vecteurs, scores):
    """Test de la comparaison des deux approches"""
    print("\n" + "="*60)
    print("TEST 7: COMPARAISON DAMA vs PROBABILISTE")
    print("="*60)

    df = create_test_dataset()
    cols = df.columns.tolist()

    comparison = comparator.compare_dama_vs_probabiliste(df, cols, scores, vecteurs)

    dama_scores = comparison.get("dama_scores", {})
    problemes = comparison.get("problemes_masques", [])
    gains = comparison.get("gains", [])

    print(f"\n   Scores DAMA calcul√©s pour {len(dama_scores)} colonnes")
    print(f"   Probl√®mes masqu√©s d√©tect√©s: {len(problemes)}")
    print(f"   Gains m√©thodologiques: {len(gains)} cat√©gories")

    # Afficher quelques scores DAMA
    for col, data in list(dama_scores.items())[:3]:
        print(f"\n   {col}:")
        print(f"      Compl√©tude: {data.get('completeness', 'N/A')}")
        print(f"      Unicit√©: {data.get('uniqueness', 'N/A')}")
        print(f"      Score global: {data.get('score_global', 'N/A')}")

    print(f"\n   ‚úì Comparaison DAMA vs Probabiliste fonctionnelle")

    return True


# ============================================================================
# TEST 8: COH√âRENCE GLOBALE
# ============================================================================

def test_coherence_globale(vecteurs, scores):
    """Test de coh√©rence globale du syst√®me"""
    print("\n" + "="*60)
    print("TEST 8: COH√âRENCE GLOBALE")
    print("="*60)

    # 1. V√©rifier que les colonnes "parfaites" ont des scores bas
    score_parfaite = scores.get("Col_Parfaite_Paie", 1)
    assert score_parfaite < 0.3, f"Col_Parfaite devrait avoir un score bas, a {score_parfaite:.1%}"
    print(f"   ‚úì Col_Parfaite a un score bas ({score_parfaite:.1%})")

    # 2. V√©rifier que les colonnes "probl√©matiques" ont des scores √©lev√©s
    score_probleme = scores.get("Col_50pct_Nulls_Paie", 0)
    print(f"   ‚úì Col_50pct_Nulls a un score de {score_probleme:.1%}")

    # 3. V√©rifier la coh√©rence entre vecteurs et scores
    for col in vecteurs.keys():
        v = vecteurs[col]

        # Si P_UP est tr√®s √©lev√©, le score Dashboard devrait √™tre impact√©
        if v.get("P_UP", 0) > 0.5:
            score_dash = scores.get(f"{col}_Dashboard", 0)
            print(f"   {col}: P_UP={v['P_UP']:.2f} ‚Üí Score Dashboard={score_dash:.1%}")

    print(f"\n   ‚úì Coh√©rence globale v√©rifi√©e")

    return True


# ============================================================================
# MAIN
# ============================================================================

def run_all_tests():
    """Ex√©cute tous les tests"""
    print("\n" + "="*60)
    print("TESTS AVANC√âS - FRAMEWORK PROBABILISTE DQ")
    print("="*60)

    results = {}

    try:
        # Test 1: Analyzer
        stats = test_analyzer()
        results["analyzer"] = "‚úÖ PASS"
    except Exception as e:
        results["analyzer"] = f"‚ùå FAIL: {e}"
        stats = None

    try:
        # Test 2: Beta Calculator
        if stats:
            vecteurs = test_beta_calculator(stats)
            results["beta_calculator"] = "‚úÖ PASS"
        else:
            results["beta_calculator"] = "‚è≠Ô∏è SKIP (d√©pend de analyzer)"
            vecteurs = None
    except Exception as e:
        results["beta_calculator"] = f"‚ùå FAIL: {e}"
        vecteurs = None

    try:
        # Test 3: AHP Elicitor
        test_ahp_elicitor()
        results["ahp_elicitor"] = "‚úÖ PASS"
    except Exception as e:
        results["ahp_elicitor"] = f"‚ùå FAIL: {e}"

    try:
        # Test 4: Risk Scorer
        if vecteurs:
            scores = test_risk_scorer(vecteurs)
            results["risk_scorer"] = "‚úÖ PASS"
        else:
            results["risk_scorer"] = "‚è≠Ô∏è SKIP (d√©pend de beta_calculator)"
            scores = None
    except Exception as e:
        results["risk_scorer"] = f"‚ùå FAIL: {e}"
        scores = None

    try:
        # Test 5: Unicit√© DAMA
        test_dama_uniqueness()
        results["dama_uniqueness"] = "‚úÖ PASS"
    except Exception as e:
        results["dama_uniqueness"] = f"‚ùå FAIL: {e}"

    try:
        # Test 6: Lineage Propagation
        if vecteurs:
            test_lineage_propagation(vecteurs)
            results["lineage"] = "‚úÖ PASS"
        else:
            results["lineage"] = "‚è≠Ô∏è SKIP"
    except Exception as e:
        results["lineage"] = f"‚ùå FAIL: {e}"

    try:
        # Test 7: DAMA vs Probabiliste
        if vecteurs and scores:
            test_dama_vs_probabiliste(vecteurs, scores)
            results["dama_vs_prob"] = "‚úÖ PASS"
        else:
            results["dama_vs_prob"] = "‚è≠Ô∏è SKIP"
    except Exception as e:
        results["dama_vs_prob"] = f"‚ùå FAIL: {e}"

    try:
        # Test 8: Coh√©rence globale
        if vecteurs and scores:
            test_coherence_globale(vecteurs, scores)
            results["coherence"] = "‚úÖ PASS"
        else:
            results["coherence"] = "‚è≠Ô∏è SKIP"
    except Exception as e:
        results["coherence"] = f"‚ùå FAIL: {e}"

    # R√©sum√©
    print("\n" + "="*60)
    print("R√âSUM√â DES TESTS")
    print("="*60)

    passed = sum(1 for r in results.values() if "PASS" in r)
    failed = sum(1 for r in results.values() if "FAIL" in r)
    skipped = sum(1 for r in results.values() if "SKIP" in r)

    for test, result in results.items():
        print(f"   {test}: {result}")

    print(f"\n   TOTAL: {passed} pass√©s, {failed} √©chou√©s, {skipped} ignor√©s")

    if failed == 0:
        print("\n   üéâ TOUS LES TESTS SONT PASS√âS !")
    else:
        print(f"\n   ‚ö†Ô∏è {failed} TEST(S) √âCHOU√â(S)")

    return results


if __name__ == "__main__":
    run_all_tests()
